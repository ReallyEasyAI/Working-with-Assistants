{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Assistants Part 1\n",
    "The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and files to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, File Search, and Function calling.\n",
    "\n",
    "A typical integration of the Assistants API has the following flow:\n",
    "\n",
    "1. Create an Assistant by defining its custom instructions and picking a model. If helpful, add files and enable tools like Code Interpreter, File Search, and Function calling.\n",
    "2. Create a Thread when a user starts a conversation.\n",
    "3. Add Messages to the Thread as the user asks questions.\n",
    "4. Run the Assistant on the Thread to generate a response by calling the model and the tools.\n",
    "\n",
    "## Calling Pre-Existing Assistants with Code\n",
    "To use a preexisting Assistant we have to get the Assistant id first. We can do this through the interface or through code. Below we show how to do this with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line and run this to make sure \n",
    "# you have the latest version of the openai package\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistant(id='asst_qGjXPL02tdAXzPyaWzNKtWdv', created_at=1714543835, description=None, instructions='You are a helpful assistant. ', metadata={}, model='gpt-4-turbo', name='SonOfAnotherAssistant', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0), Assistant(id='asst_13I9T9OHsZVIx9G2Ja7AKXVc', created_at=1714543766, description=None, instructions='You are a helpful assistant. ', metadata={}, model='gpt-4-turbo', name='YetAnotherAssistant', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0), Assistant(id='asst_jrcAIIKpz1O8s5GKuMMKawAx', created_at=1714348610, description=None, instructions='You are a helpful assistant.', metadata={}, model='gpt-4-turbo', name='Function Fun', object='assistant', tools=[FunctionTool(function=FunctionDefinition(name='get_weather', description='Determine weather in my location', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['c', 'f']}}, 'required': ['location']}), type='function')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0), Assistant(id='asst_sZiMAv1OmVpN464k2JoxyjdB', created_at=1714348320, description=None, instructions='You are a helpful assistant.', metadata={}, model='gpt-4-turbo', name='Code Brutha', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-zANRT5ylCOIKzeFzV3HpJBru']), file_search=None), top_p=1.0), Assistant(id='asst_hlsbSbcxUitk2IF36G5KOi0H', created_at=1714347804, description=None, instructions='You are a helpful assistant that answers questions based on the files that you have available to you. ', metadata={}, model='gpt-4-turbo', name='File Search Assistant', object='assistant', tools=[FileSearchTool(type='file_search')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_3OD2BXxllkqiuVflGii9woHS'])), top_p=1.0), Assistant(id='asst_2Y9kU1ZtaqtHNbNm83s78CV1', created_at=1714347606, description=None, instructions='Vox Antiqua excels in translating any phrase into Ancient Latin, emphasizing adaptation to fit the cultural and historical context of the time. It aims to provide translations that reflect how the phrase would have been expressed authentically in ancient times, rather than just literal translations. This approach involves a deep understanding of the nuances of both the source language and Ancient Latin, including idiomatic, historical, literary, or everyday expressions. Vox Antiqua avoids modern interpretations unless specifically requested. For ambiguous or unclear inputs, it seeks clarification to ensure accuracy. It avoids engaging with inappropriate content or topics that do not align with its purpose of translation.', metadata={}, model='gpt-4-turbo', name='Vox Antiqua', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)]\n",
      "\n",
      "\n",
      "\n",
      "Name: SonOfAnotherAssistant, ID: asst_qGjXPL02tdAXzPyaWzNKtWdv\n",
      "Name: YetAnotherAssistant, ID: asst_13I9T9OHsZVIx9G2Ja7AKXVc\n",
      "Name: Function Fun, ID: asst_jrcAIIKpz1O8s5GKuMMKawAx\n",
      "Name: Code Brutha, ID: asst_sZiMAv1OmVpN464k2JoxyjdB\n",
      "Name: File Search Assistant, ID: asst_hlsbSbcxUitk2IF36G5KOi0H\n",
      "Name: Vox Antiqua, ID: asst_2Y9kU1ZtaqtHNbNm83s78CV1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenAI class from the openai module.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create an instance of the OpenAI class.\n",
    "# NOTE: This assumes you have an OPENAI_API_KEY environment variable set.\n",
    "client = OpenAI()\n",
    "\n",
    "# Retrieve a list of AI assistants available under your account in descending order.\n",
    "# The list is limited to the top 20 assistants.\n",
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=20  # Ensure limit is an integer, not a string\n",
    ")\n",
    "\n",
    "# Print the data attribute from the my_assistants object to display the assistants.\n",
    "print(my_assistants.data)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Iterate through each assistant in the list and print its name and ID.\n",
    "for assistant in my_assistants.data:\n",
    "    print(f\"Name: {assistant.name}, ID: {assistant.id}\")\n",
    "\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can retrieve the Assistant by the id number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_2Y9kU1ZtaqtHNbNm83s78CV1', created_at=1714347606, description=None, instructions='Vox Antiqua excels in translating any phrase into Ancient Latin, emphasizing adaptation to fit the cultural and historical context of the time. It aims to provide translations that reflect how the phrase would have been expressed authentically in ancient times, rather than just literal translations. This approach involves a deep understanding of the nuances of both the source language and Ancient Latin, including idiomatic, historical, literary, or everyday expressions. Vox Antiqua avoids modern interpretations unless specifically requested. For ambiguous or unclear inputs, it seeks clarification to ensure accuracy. It avoids engaging with inappropriate content or topics that do not align with its purpose of translation.', metadata={}, model='gpt-4-turbo', name='Vox Antiqua', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Vox Antiqua\n",
      "None\n",
      "1714347606\n",
      "2024-04-28 13:40:06 CDT\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the below line and run this to make sure\n",
    "# you have the pytz package installed which is used \n",
    "# for timezone conversion\n",
    "# !pip install pytz\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Import the OpenAI class from the openai module.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create an instance of the OpenAI class.\n",
    "client = OpenAI()\n",
    "\n",
    "# Retrieve a specific assistant using its unique identifier.\n",
    "my_assistant = client.beta.assistants.retrieve(\"asst_2Y9kU1ZtaqtHNbNm83s78CV1\")\n",
    "\n",
    "# Print the retrieved assistant to display its details.\n",
    "print(my_assistant)\n",
    "print(\"\\n\\n\")\n",
    "print(my_assistant.name)\n",
    "print(my_assistant.description)\n",
    "print(my_assistant.created_at)\n",
    "\n",
    "# grab the created date/time in unix format \n",
    "# and convert it to a human readable format\n",
    "unix_time = my_assistant.created_at\n",
    "\n",
    "# Create a timezone object for Central Time\n",
    "central_timezone = pytz.timezone('America/Chicago')\n",
    "\n",
    "# Convert Unix time to a datetime object in UTC\n",
    "utc_date = datetime.datetime.fromtimestamp(unix_time)\n",
    "\n",
    "# Localize the UTC datetime object to Central Time\n",
    "central_date = utc_date.replace(tzinfo=pytz.utc).astimezone(central_timezone)\n",
    "\n",
    "# Format the datetime object to a readable string\n",
    "formatted_date = central_date.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "\n",
    "print(formatted_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Assistants Part 2\n",
    "## Creating a Minimalist Assistant\n",
    "Let's begin by creating an Assistant through code. As a reminder, you can also create Assistants through the user interface at https://platform.openai.com/assistants as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_Yn1nYwZUaTKcboLOqAj94eGf', created_at=1714546348, description=None, instructions=None, metadata={}, model='gpt-4-turbo', name=None, object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenAI class from the openai module.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create an instance of the OpenAI class.\n",
    "# NOTE: Make sure you have an environment variable, \n",
    "# called OPENAI_API_KEY set with your API key before running this code.\n",
    "client = OpenAI()\n",
    "\n",
    "# Create an assistant specifying only the required 'model' parameter.\n",
    "# The 'model' is set to 'gpt-4-turbo'. All other parameters are optional and not specified here.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    ")\n",
    "\n",
    "# The 'assistant' object now contains information about the newly created assistant.\n",
    "# You could add code here to handle or display the 'assistant' object as needed, for example:\n",
    "print(assistant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: None, ID: asst_Yn1nYwZUaTKcboLOqAj94eGf\n",
      "Name: SonOfAnotherAssistant, ID: asst_qGjXPL02tdAXzPyaWzNKtWdv\n",
      "Name: YetAnotherAssistant, ID: asst_13I9T9OHsZVIx9G2Ja7AKXVc\n",
      "Name: Function Fun, ID: asst_jrcAIIKpz1O8s5GKuMMKawAx\n",
      "Name: Code Brutha, ID: asst_sZiMAv1OmVpN464k2JoxyjdB\n",
      "Name: File Search Assistant, ID: asst_hlsbSbcxUitk2IF36G5KOi0H\n",
      "Name: Vox Antiqua, ID: asst_2Y9kU1ZtaqtHNbNm83s78CV1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenAI class from the openai module.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create an instance of the OpenAI class.\n",
    "# NOTE: This assumes you have an OPENAI_API_KEY environment variable set.\n",
    "client = OpenAI()\n",
    "\n",
    "# Retrieve a list of AI assistants available under your account in descending order.\n",
    "# The list is limited to the top 20 assistants.\n",
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=20  # Ensure limit is an integer, not a string\n",
    ")\n",
    "\n",
    "# Iterate through each assistant in the list and print its name and ID.\n",
    "for assistant in my_assistants.data:\n",
    "    print(f\"Name: {assistant.name}, ID: {assistant.id}\")\n",
    "\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Basic Assistant\n",
    "\n",
    "Now let's create an Assistant with the following arguments:\n",
    "\n",
    "**model**\n",
    "(string)\n",
    "\n",
    "*Required*\n",
    "\n",
    "ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n",
    "\n",
    "---\n",
    "\n",
    "**name**\n",
    "(string or null)\n",
    "\n",
    "*Optional*\n",
    "\n",
    "The name of the assistant. The maximum length is 256 characters.\n",
    "\n",
    "---\n",
    "\n",
    "**description**\n",
    "(string or null)\n",
    "\n",
    "*Optional*\n",
    "\n",
    "The description of the assistant. The maximum length is 512 characters.\n",
    "\n",
    "---\n",
    "\n",
    "**instructions**\n",
    "(string or null)\n",
    "\n",
    "*Optional*\n",
    "\n",
    "The system instructions that the assistant uses. The maximum length is 256,000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_pmBVVKeAfY9ka1GA5CVlhPxL', created_at=1714546591, description='This is a seriously cool assistant', instructions='You are a helpful assistant.', metadata={}, model='gpt-4-turbo', name='Seriously Cool Assistant', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Seriously Cool Assistant\n",
      "This is a seriously cool assistant\n",
      "You are a helpful assistant.\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenAI class from the openai module.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create an instance of the OpenAI class.\n",
    "client = OpenAI()\n",
    "\n",
    "# Create an assistant with a basic configuration\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    name=\"Seriously Cool Assistant\",\n",
    "    description=\"This is a seriously cool assistant\",\n",
    "    instructions=\"You are a helpful assistant.\"\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant object to check the creation status and attributes.\n",
    "print(assistant)\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)\n",
    "print(assistant.description)\n",
    "print(assistant.instructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Arguments\n",
    "**metadata**\n",
    "(map)\n",
    "\n",
    "*Optional*\n",
    "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n",
    "\n",
    "---\n",
    "\n",
    "**temperature**\n",
    "(number or null)\n",
    "\n",
    "*Optional*\n",
    "(Defaults to 1)\n",
    "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "\n",
    "---\n",
    "\n",
    "**top_p**\n",
    "(number or null)\n",
    "\n",
    "*Optional*\n",
    "(Defaults to 1)\n",
    "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n",
    "\n",
    "---\n",
    "\n",
    "**response_format**\n",
    "(string or object)\n",
    "\n",
    "*Optional*\n",
    "(Defaults to \"auto\")\n",
    "Specifies the format that the model must output. Compatible with GPT-4 Turbo and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n",
    "\n",
    "Setting to { \"type\": \"json_object\" } enables JSON mode, which guarantees the message the model generates is valid JSON.\n",
    "\n",
    "Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_WUedegb2r56SruQ4mYerGdXs', created_at=1714547052, description='This assistant has extra arguments', instructions='You are a helpful assistant.', metadata={'key': 'value', 'IsAwesome': 'True', 'IsBeta': 'False'}, model='gpt-4-turbo', name='Extra Arguments Assistant', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Extra Arguments Assistant\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenAI class from the openai module.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Make sure you have the latest version of the OpenAI Python SDK installed.\n",
    "# To update, run: pip install openai --upgrade\n",
    "\n",
    "# Create an instance of the OpenAI class.\n",
    "cool_assistant = OpenAI()\n",
    "\n",
    "# Create an assistant with a comprehensive set of arguments\n",
    "cool_assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    name=\"Extra Arguments Assistant\",\n",
    "    description=\"This assistant has extra arguments\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    metadata={\n",
    "        \"key\": \"value\",\n",
    "        \"IsAwesome\": \"True\",\n",
    "        \"IsBeta\": \"False\"\n",
    "    },\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    response_format=\"auto\",\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to verify its properties.\n",
    "print(cool_assistant)\n",
    "print(\"\\n\\n\")\n",
    "print(cool_assistant.name)\n",
    "print(cool_assistant.temperature)\n",
    "print(cool_assistant.top_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Tools\n",
    "**tools**\n",
    "(array)\n",
    "\n",
    "*Optional*\n",
    "(Defaults to [])\n",
    "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, file_search, or function.\n",
    "\n",
    "---\n",
    "\n",
    "**tool_resources**\n",
    "(object or null)\n",
    "\n",
    "*Optional*\n",
    "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_5aEb1Hk1RA3MNU4j5kzshyZ3', created_at=1714547305, description=None, instructions='You are a personal data analyst. When asked a question, write and run Python code to answer the question.', metadata={'key': 'value', 'is_awesome': 'True', 'is_beta': 'False'}, model='gpt-4-turbo', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "[CodeInterpreterTool(type='code_interpreter')]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create an instance of the OpenAI class.\n",
    "client = OpenAI()\n",
    "\n",
    "# Create an assistant that uses code interpreter.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    instructions=\"You are a personal data analyst. When asked a question, write and run Python code to answer the question.\",\n",
    "    name=\"Code Interpreter Assistant\",\n",
    "    metadata={\n",
    "        \"key\": \"value\",\n",
    "        \"is_awesome\": \"True\",  # Lowercase dictionary keys\n",
    "        \"is_beta\": \"False\"\n",
    "    },\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    response_format=\"auto\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources=None,\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check the properties.\n",
    "print(assistant)\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)\n",
    "print(assistant.tools)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
