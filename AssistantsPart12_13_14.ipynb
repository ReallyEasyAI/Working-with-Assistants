{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 12\n",
    "\n",
    "# Using File Search\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants\n",
    "\n",
    "import re # Used for regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handler class to handle events related to streaming output from the assistant\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nASSISTANT MESSAGE >\\n\", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nASSISTANT MESSAGE >\\n{tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload files for later use\n",
    "alice_file = client.files.create(file=open(\"./artifacts/Alice_in_Wonderland.pdf\",\"rb\"), purpose=\"assistants\")\n",
    "oz_file = client.files.create(file=open(\"./artifacts/The_Wonderful_Wizard_of_Oz.txt\",\"rb\"), purpose=\"assistants\")\n",
    "dracula_file = client.files.create(file=open(\"./artifacts/Dracula.pdf\",\"rb\"), purpose=\"assistants\")\n",
    "frank_file = client.files.create(file=open(\"./artifacts/Frankenstein.pdf\",\"rb\"), purpose=\"assistants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice_in_Wonderland.pdf\n",
      "file-0FIEIREs7FBx2I0JWTCvX6lr\n",
      "\n",
      "\n",
      "The_Wonderful_Wizard_of_Oz.txt\n",
      "file-G9SKXdqujcOdgPLxZVsIYvyH\n",
      "\n",
      "\n",
      "Dracula.pdf\n",
      "file-2Pt5p1we3eN6PbnVGfkHrX4W\n",
      "\n",
      "\n",
      "Frankenstein.pdf\n",
      "file-qvUMg5D47GSGgxieOHPPswx1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(alice_file.filename)\n",
    "print(alice_file.id)\n",
    "print(\"\\n\")\n",
    "print(oz_file.filename)\n",
    "print(oz_file.id)\n",
    "print(\"\\n\")\n",
    "print(dracula_file.filename)\n",
    "print(dracula_file.id)\n",
    "print(\"\\n\")\n",
    "print(frank_file.filename)\n",
    "print(frank_file.id)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Assistant with File Search enabled\n",
    "\n",
    "Our first step is to create an Assistant that can do file searching regardless of where the vector store resides (Assistant or Thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_DoFXrEezZFG3QxW5mhvvtTFp', created_at=1717674131, description=None, instructions=' \\n        You are a helpful assistant that answers questions about the stories in your files. The stories are from a variety of authors. \\n        You will answer questions from the user about the stories. All you will do is answer questions about the stories in the files and provide related information.\\n        If the user asks you a question that is not related to the stories in the files, you should let them know that you can only answer questions about the stories.\\n    ', metadata={'can_be_used_for_file_search': 'True', 'can_hold_vector_store': 'True'}, model='gpt-4o', name='File Search Demo Assistant - Stories', object='assistant', tools=[FileSearchTool(type='file_search', file_search=None)], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=[])), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "File Search Demo Assistant - Stories\n",
      "{'can_be_used_for_file_search': 'True', 'can_hold_vector_store': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant that answers questions about the stories in your files. The stories are from a variety of authors. \n",
    "        You will answer questions from the user about the stories. All you will do is answer questions about the stories in the files and provide related information.\n",
    "        If the user asks you a question that is not related to the stories in the files, you should let them know that you can only answer questions about the stories.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"File Search Demo Assistant - Stories\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"file_search\"}], # Add the file search capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_file_search\": \"True\",\n",
    "        \"can_hold_vector_store\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Vector Store\n",
    "\n",
    "Now we will create our vector store to hold our files and add files at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great Fiction Stories\n",
      "vs_4VB1NSiJioJqeA74T9DQAKJJ\n",
      "completed\n",
      "FileCounts(cancelled=0, completed=2, failed=0, in_progress=0, total=2)\n"
     ]
    }
   ],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "# Create a vector store with a name for the store.\n",
    "vector_store = client.beta.vector_stores.create(name=\"Great Fiction Stories\")\n",
    "\n",
    "# Ready the files for upload to the vector store.\n",
    "file_paths = [\"./artifacts/I_Am_Legend.pdf\", \"./artifacts/The_Veldt.pdf\"]\n",
    "\n",
    "# Using ExitStack to manage multiple context managers and ensure they are properly closed.\n",
    "with ExitStack() as stack:\n",
    "    # Open each file in binary read mode and add the file stream to the list\n",
    "    file_streams = [stack.enter_context(open(path, \"rb\")) for path in file_paths]\n",
    "\n",
    "    # Use the upload and poll helper method to upload the files, add them to the vector store,\n",
    "    # and poll the status of the file batch for completion.\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=file_streams\n",
    "    )\n",
    "\n",
    "    # Print the vector store information\n",
    "    print(vector_store.name)\n",
    "    print(vector_store.id)\n",
    "    \n",
    "    # Print the status and the file counts of the batch to see the results\n",
    "    print(file_batch.status)\n",
    "    print(file_batch.file_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 13\n",
    "\n",
    "### Attaching the Vector Store to the Assistant\n",
    "\n",
    "We have an Assistant that has File Search enabled and we have a Vector Store with files in them. It's time to join the two up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant Tools:\n",
      " - FileSearchTool(type='file_search', file_search=None)\n",
      "\n",
      "Assistant Tool Resources:\n",
      " - code_interpreter: None\n",
      " - file_search: ToolResourcesFileSearch(vector_store_ids=['vs_4VB1NSiJioJqeA74T9DQAKJJ'])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Attach the vector store to the assistant to enable file search capabilities.\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant.id,\n",
    "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "    )\n",
    "\n",
    "    # Print the assistant's tools and tool resources to verify the attachment of the vector store.\n",
    "    print(\"Assistant Tools:\")\n",
    "    for tool in assistant.tools:\n",
    "        print(f\" - {tool}\")\n",
    "\n",
    "    # Print the assistant's tool resources to verify the attachment of the vector store\n",
    "    print(\"\\nAssistant Tool Resources:\")\n",
    "    for resource, details in assistant.tool_resources:\n",
    "        print(f\" - {resource}: {details}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while updating the assistant: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Assistant and Vector Store at the Same Time\n",
    "\n",
    "If we have file id's we can just feed them in when creating an assistant to get the Assistant and the Vector Store at the same time using the vector_stores option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_Xqe7RKL94sA7oI3jQcI47Qor', created_at=1717687018, description=None, instructions='You are a helpful assistant that answers questions about the stories in your files. The stories are from a variety of authors. You will answer questions from the user about the stories. All you will do is answer questions about the stories in the files and provide related information. If the user asks you a question that is not related to the stories in the files, you should let them know that you can only answer questions about the stories.', metadata={'can_be_used_for_file_search': 'True', 'has_vector_store': 'True'}, model='gpt-4o', name='Quick Assistant and Vector Store at Once', object='assistant', tools=[FileSearchTool(type='file_search', file_search=None)], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_gG4yDnQuxf5JwD6jPwilnPDz'])), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Assistant Name: Quick Assistant and Vector Store at Once\n",
      "\n",
      "\n",
      "Vector Store Name: Vector Store Auto Attached to Assistant\n",
      "Vector Store Id: vs_gG4yDnQuxf5JwD6jPwilnPDz\n",
      "Vector Store Metadata: {'Book1': 'Wizard of Oz', 'Book2': 'Alice in Wonderland'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an assistant using the client library.\n",
    "try:\n",
    "    assistant_with_vector_store = client.beta.assistants.create(\n",
    "        model=\"gpt-4o\",  # Specify the model to be used.\n",
    "        instructions=(\n",
    "            \"You are a helpful assistant that answers questions about the stories in your files. \"\n",
    "            \"The stories are from a variety of authors. \"\n",
    "            \"You will answer questions from the user about the stories. All you will do is answer questions about the stories in the files and provide related information. \"\n",
    "            \"If the user asks you a question that is not related to the stories in the files, you should let them know that you can only answer questions about the stories.\"\n",
    "        ),\n",
    "        name=\"Quick Assistant and Vector Store at Once\",  # Give the assistant a name.\n",
    "        tools=[{\"type\": \"file_search\"}],  # Add the file search capability to the assistant.\n",
    "        # Create a vector store and attach it to the assistant in one step.\n",
    "        tool_resources={\n",
    "            \"file_search\": {\n",
    "                \"vector_stores\": [\n",
    "                    {\n",
    "                        \"name\": \"Vector Store Auto Attached to Assistant\",\n",
    "                        \"file_ids\": [\n",
    "                            oz_file.id,\n",
    "                            alice_file.id\n",
    "                        ],\n",
    "                        \"metadata\": {\n",
    "                            \"Book1\": \"Wizard of Oz\", \n",
    "                            \"Book2\": \"Alice in Wonderland\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        metadata={  # Add metadata about the assistant's capabilities.\n",
    "            \"can_be_used_for_file_search\": \"True\",\n",
    "            \"has_vector_store\": \"True\",\n",
    "        },\n",
    "        temperature=1,  # Set the temperature for response variability.\n",
    "        top_p=1,  # Set the top_p for nucleus sampling.\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating the assistant: {e}\")\n",
    "else:\n",
    "    # Print the details of the created assistant to check its properties.\n",
    "    print(assistant_with_vector_store)  # Print the full assistant object.\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Assistant Name: \" + assistant_with_vector_store.name)  # Print the name of the assistant.\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # get the vector store information\n",
    "    unnamed_assistant_vector_store = client.beta.vector_stores.retrieve(assistant_with_vector_store.tool_resources.file_search.vector_store_ids[0])\n",
    "    print(\"Vector Store Name: \" + str(unnamed_assistant_vector_store.name))\n",
    "    print(\"Vector Store Id: \" + unnamed_assistant_vector_store.id)\n",
    "    print(\"Vector Store Metadata: \" + str(unnamed_assistant_vector_store.metadata))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Threads with Vector Stores\n",
    "\n",
    "### Creating Vector Stores with Thread Messages\n",
    "\n",
    "You can create a vector store in threads with one of two ways: messages or during thread creation. If you create a thread with a vector store then it will also be searched when looking for information during the run. First, let's take a look at the most common scenario, vector stores created with messages in the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Auto Attached to Thread When Message File Attached\n",
      "vs_W0nvRHVEeomtdrpL2PMh1Pne\n",
      "vs_W0nvRHVEeomtdrpL2PMh1Pne\n"
     ]
    }
   ],
   "source": [
    "# We assume that the user has given us a file to upload\n",
    "message_file = client.files.create(\n",
    "    file=open(\"./artifacts/War_of_the_Worlds.txt\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread_with_file_attachment = client.beta.threads.create(\n",
    "    messages=[\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"List all the books you have access to in your files.\",\n",
    "    \n",
    "    # Attach the new file to the message.\n",
    "    \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "    ],\n",
    "    }\n",
    "]\n",
    ")\n",
    "\n",
    "# Give the vector store a friendly name for easy reference.\n",
    "updated_vector_store = client.beta.vector_stores.update(\n",
    "    vector_store_id=thread_with_file_attachment.tool_resources.file_search.vector_store_ids[0],\n",
    "    name=\"Vector Store Auto Attached to Thread When Message File Attached\",\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(updated_vector_store.name)\n",
    "print(updated_vector_store.id)\n",
    "\n",
    "# Alternate way to get the vector store id from the thread\n",
    "print(thread_with_file_attachment.tool_resources.file_search.vector_store_ids[0])   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vector Stores at Thread Creation Time\n",
    "\n",
    "Now, let's look at creating a vector store when we create our thread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_F0tueXawpqN9BAowCaD8Y3mr', created_at=1717688420, metadata={'can_be_used_for_file_search': 'True', 'has_vector_store': 'True'}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_BczptHYs6oRzTNYmeHsjFDIo'])))\n",
      "\n",
      "\n",
      "Thread ID: thread_F0tueXawpqN9BAowCaD8Y3mr\n",
      "Thread Metadata: {'can_be_used_for_file_search': 'True', 'has_vector_store': 'True'}\n",
      "Thread Tool Resources: ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_BczptHYs6oRzTNYmeHsjFDIo']))\n"
     ]
    }
   ],
   "source": [
    "thread_with_vector_store = client.beta.threads.create(\n",
    "    messages=[\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"List every book you have access to. Just give me the list and nothing else. Then tell me who the main character was in each book\",\n",
    "    }\n",
    "    ],\n",
    "    tool_resources={\n",
    "            \"file_search\": {\n",
    "                \"vector_stores\": [\n",
    "                    {\n",
    "                        \"name\": \"Vector Store Auto Attached to Thread\",\n",
    "                        \"file_ids\": [\n",
    "                            dracula_file.id,\n",
    "                            frank_file.id\n",
    "                        ],\n",
    "                        \"metadata\": {\n",
    "                            \"Book1\": \"Dracula\", \n",
    "                            \"Book2\": \"Frankenstein\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        metadata={  # Add metadata about the assistant's capabilities.\n",
    "            \"can_be_used_for_file_search\": \"True\",\n",
    "            \"has_vector_store\": \"True\",\n",
    "        },\n",
    ")\n",
    "\n",
    "# Print the details of the created thread to check its properties\n",
    "print(thread_with_vector_store)  # Print the full thread object.\n",
    "print(\"\\n\")\n",
    "print(\"Thread ID: \" + thread_with_vector_store.id)  # Print the ID of the thread.\n",
    "print(\"Thread Metadata: \" + str(thread_with_vector_store.metadata))  # Print the metadata of the thread.\n",
    "print(\"Thread Tool Resources: \" + str(thread_with_vector_store.tool_resources))  # Print the tool resources of the thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Results\n",
    "\n",
    "We have built up Assistants and Threads with vector stores and now we want to use them. We need to set up a run to make this happen. Recall there are two approaches: streaming or non-streaming. We will do both.\n",
    "\n",
    "### Streaming Run\n",
    "\n",
    "First, let's do the, more common, streaming run to get our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSISTANT MESSAGE >\n",
      "file_search\n",
      "\n",
      "\n",
      "ASSISTANT MESSAGE >\n",
      "### Book List:\n",
      "1. Frankenstein by Mary Wollstonecraft Shelley\n",
      "2. Dracula by Bram Stoker\n",
      "\n",
      "### Main Characters:\n",
      "1. **Frankenstein**:\n",
      "    - Main Character: Victor Frankenstein[0]\n",
      "2. **Dracula**:\n",
      "    - Main Characters: Jonathan Harker, Mina Murray, and Count Dracula[1]\n",
      "[0] Frankenstein.pdf\n",
      "[1] Dracula.pdf\n"
     ]
    }
   ],
   "source": [
    "# Using our first assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread_with_vector_store.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant. \n",
    "    ALWAYS read all the files you have before answering questions about them. \n",
    "    Only answer the user's question about the information you have in your files.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Without Streaming\n",
    "\n",
    "Now let's do a run without streaming to compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the book titles I have access to from your files:\n",
      "\n",
      "1. *Alice's Adventures in Wonderland* by Lewis Carroll\n",
      "2. *Through the Looking-Glass, and What Alice Found There* by Lewis Carroll\n",
      "3. *The Wonderful Wizard of Oz* by L. Frank Baum\n",
      "4. *The War of the Worlds* by H. G. Wells   .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use our second assistant\n",
    "# Use the create and poll SDK helper to create a run and poll the status of\n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread_with_file_attachment.id, assistant_id=assistant_with_vector_store.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread_with_file_attachment.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 14\n",
    "\n",
    "## Creating a Simple Vector Store\n",
    "\n",
    "Let's create the bare minimum vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore(id='vs_W1dbdzPZ2bxbVMp5DlSVw3XH', created_at=1717702882, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1717702882, metadata={}, name=None, object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None)\n"
     ]
    }
   ],
   "source": [
    "# Absolute minimum example of creating a vector store\n",
    "vector_store = client.beta.vector_stores.create(\n",
    ")\n",
    "print(vector_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Expiration\n",
    "\n",
    "If your vector store has a time limit, you can set and expiration for it. Vector stores created with threads or messages have a default expiration of 7 days by default. Normal vector stores do not have an expiration by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore(id='vs_xMm4BzNCxOmyZFzQzwTv8qVV', created_at=1717703026, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1717703026, metadata={}, name='Dead Vector Store Walking', object='vector_store', status='completed', usage_bytes=0, expires_after=ExpiresAfter(anchor='last_active_at', days=10), expires_at=1718567026)\n"
     ]
    }
   ],
   "source": [
    "# Setting a name and expiration time for the vector store\n",
    "vector_store = client.beta.vector_stores.create(\n",
    "    name=\"Dead Vector Store Walking\",\n",
    "    expires_after={\n",
    "        \"anchor\": \"last_active_at\",\n",
    "        \"days\": 10\n",
    "    }\n",
    ")\n",
    "print(vector_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking Strategy\n",
    "\n",
    "Time to see how we would implement a chunking strategy without the Auto turned on. In this case, we set \"type\" to \"static\" and then indicate the parameters for chunk size and overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore(id='vs_TJIE828UbugAfJvpiC38SBru', created_at=1717703407, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1717703407, metadata={}, name=None, object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store with static chunking strategy\n",
    "vector_store = client.beta.vector_stores.create(\n",
    "    chunking_strategy={\n",
    "        \"type\": \"static\",\n",
    "        \"static\": {\n",
    "            \"max_chunk_size_tokens\": 1000,  # Customize these values as needed\n",
    "            \"chunk_overlap_tokens\": 500    # Customize these values as needed\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Vector Stores\n",
    "\n",
    "It's important to be able to list our vector stores so we can work with them in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Stores: 10\n",
      "Name: None\n",
      "ID: vs_TJIE828UbugAfJvpiC38SBru\n",
      "\n",
      "\n",
      "Name: Dead Vector Store Walking\n",
      "ID: vs_xMm4BzNCxOmyZFzQzwTv8qVV\n",
      "\n",
      "\n",
      "Name: None\n",
      "ID: vs_W1dbdzPZ2bxbVMp5DlSVw3XH\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_BczptHYs6oRzTNYmeHsjFDIo\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_OH3COfzRDcLMKKLRuDUK1mj0\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_FiJTdq7OSNBdp5UOgWCJoIsE\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_Cj2J7ZDAgyxrc213nN58pjyJ\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread When Message File Attached\n",
      "ID: vs_W0nvRHVEeomtdrpL2PMh1Pne\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Assistant\n",
      "ID: vs_gG4yDnQuxf5JwD6jPwilnPDz\n",
      "\n",
      "\n",
      "Name: Great Fiction Stories\n",
      "ID: vs_4VB1NSiJioJqeA74T9DQAKJJ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of our vector stores up to the limit\n",
    "# The default page limit is 100, but we can specify a different limit\n",
    "# Use \"after\" to go through more than 100 vector stores\n",
    "vector_stores = client.beta.vector_stores.list()\n",
    "\n",
    "# Convert the SyncCursorPage to a list to get the number of \n",
    "# vector stores in the current page\n",
    "vector_store_list = list(vector_stores.data)\n",
    "\n",
    "# Show the number of vector stores in the current page\n",
    "print(\"Vector Stores: \" + str(len(vector_store_list)))\n",
    "\n",
    "# Loop through the vector stores in the current page\n",
    "# and print their names and IDs\n",
    "for vector_store in vector_store_list:\n",
    "    print(\"Name: \" + str(vector_store.name))\n",
    "    print(\"ID: \" + str(vector_store.id))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Vector Stores\n",
    "\n",
    "Given any vector store id, we can retrieve a vector store. Let's get creative and get a vector store id using it's name and regular expressions. This assumes you have done the prior cells in this notebook and now want to get the vector store id for a particular vector store with a name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiction Store ID: vs_4VB1NSiJioJqeA74T9DQAKJJ\n",
      "Retrieved Fiction Store Name: Great Fiction Stories\n",
      "Retrieved Fiction Store ID: vs_4VB1NSiJioJqeA74T9DQAKJJ\n"
     ]
    }
   ],
   "source": [
    "# Since we retrieved a list of vector stores in the previous example, let's leverage that list to find a specific vector store\n",
    "# We will look for a vector store with a specific name, like \"Fiction\",  using a regular expression and print its ID\n",
    "\n",
    "\n",
    "# Filter the list to find stores with names that match the pattern \"Fiction\" (case insensitive), ignoring NoneType names\n",
    "list_of_fiction_stores = [store for store in vector_store_list if store.name is not None and re.search(\"[Ff]iction\", store.name)]\n",
    "\n",
    "# Check to see if we found any stores\n",
    "if list_of_fiction_stores:\n",
    "    fiction_store = list_of_fiction_stores[0]\n",
    "    print(\"Fiction Store ID: \" + fiction_store.id)\n",
    "    \n",
    "    # Now let's retrieve the vector store using the ID of the fiction store found\n",
    "    retrieved_fiction_vector_store = client.beta.vector_stores.retrieve(vector_store_id=fiction_store.id)\n",
    "    \n",
    "    # Print the name and id of the retrieved vector store\n",
    "    if retrieved_fiction_vector_store.name is not None:\n",
    "        print(\"Retrieved Fiction Store Name: \" + retrieved_fiction_vector_store.name)\n",
    "    else:\n",
    "        print(\"Retrieved Fiction Store has no name\")\n",
    "        \n",
    "    print(\"Retrieved Fiction Store ID: \" + retrieved_fiction_vector_store.id)\n",
    "else:    \n",
    "    print(\"No Fiction Store Found\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Vector Stores\n",
    "\n",
    "Now that we have retrieved the vector store that we wanted, let's modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Name: Great Fiction Stories\n",
      "Vector Store ID: vs_4VB1NSiJioJqeA74T9DQAKJJ\n",
      "Vector Store Metadata: {}\n",
      "Vector Store Expires After: None\n",
      "\n",
      "\n",
      "Updated Vector Store Name: Great Fiction Stories\n",
      "Updated Vector Store ID: vs_4VB1NSiJioJqeA74T9DQAKJJ\n",
      "Updated Vector Store Metadata: {'Genre': 'Science Fiction', 'Book1': 'I Am Legend', 'Book2': 'The Veldt'}\n",
      "Updated Vector Store Expires After: ExpiresAfter(anchor='last_active_at', days=5)\n"
     ]
    }
   ],
   "source": [
    "# Show the vector store information\n",
    "print(\"Vector Store Name: \" + retrieved_fiction_vector_store.name)\n",
    "print(\"Vector Store ID: \" + retrieved_fiction_vector_store.id)\n",
    "print(\"Vector Store Metadata: \" + str(retrieved_fiction_vector_store.metadata))\n",
    "print(\"Vector Store Expires After: \" + str(retrieved_fiction_vector_store.expires_after))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Update the vector store with an expiration and some new metadata\n",
    "updated_fiction_vector_store = client.beta.vector_stores.update(\n",
    "    vector_store_id=retrieved_fiction_vector_store.id,\n",
    "    expires_after={\n",
    "        \"anchor\": \"last_active_at\",\n",
    "        \"days\": 5\n",
    "    },\n",
    "    metadata={\n",
    "        \"Genre\": \"Science Fiction\",\n",
    "        \"Book1\": \"I Am Legend\",\n",
    "        \"Book2\": \"The Veldt\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Show the updated vector store information\n",
    "print(\"Updated Vector Store Name: \" + updated_fiction_vector_store.name)\n",
    "print(\"Updated Vector Store ID: \" + updated_fiction_vector_store.id)\n",
    "print(\"Updated Vector Store Metadata: \" + str(updated_fiction_vector_store.metadata))\n",
    "print(\"Updated Vector Store Expires After: \" + str(updated_fiction_vector_store.expires_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Vector Store\n",
    "\n",
    "Inevitably we will want to get rid of vector stores to keep our environment clean. We have decided to get rid of any Assistant with the word \"Attached\" in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Stores: 10\n",
      "Name: None\n",
      "ID: vs_TJIE828UbugAfJvpiC38SBru\n",
      "\n",
      "\n",
      "Name: Dead Vector Store Walking\n",
      "ID: vs_xMm4BzNCxOmyZFzQzwTv8qVV\n",
      "\n",
      "\n",
      "Name: None\n",
      "ID: vs_W1dbdzPZ2bxbVMp5DlSVw3XH\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_BczptHYs6oRzTNYmeHsjFDIo\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_OH3COfzRDcLMKKLRuDUK1mj0\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_FiJTdq7OSNBdp5UOgWCJoIsE\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread\n",
      "ID: vs_Cj2J7ZDAgyxrc213nN58pjyJ\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Thread When Message File Attached\n",
      "ID: vs_W0nvRHVEeomtdrpL2PMh1Pne\n",
      "\n",
      "\n",
      "Name: Vector Store Auto Attached to Assistant\n",
      "ID: vs_gG4yDnQuxf5JwD6jPwilnPDz\n",
      "\n",
      "\n",
      "Name: Great Fiction Stories\n",
      "ID: vs_4VB1NSiJioJqeA74T9DQAKJJ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of our vector stores up to the limit\n",
    "# The default page limit is 100, but we can specify a different limit\n",
    "# Use \"after\" to go through more than 100 vector stores\n",
    "more_vector_stores = client.beta.vector_stores.list()\n",
    "\n",
    "# Convert the SyncCursorPage to a list to get the number of \n",
    "# vector stores in the current page\n",
    "more_vector_store_list = list(vector_stores.data)\n",
    "\n",
    "# Show the number of vector stores in the current page\n",
    "print(\"Vector Stores: \" + str(len(vector_store_list)))\n",
    "\n",
    "# Loop through the vector stores in the current page\n",
    "# and print their names and IDs\n",
    "for vector_store in more_vector_store_list:\n",
    "    print(\"Name: \" + str(vector_store.name))\n",
    "    print(\"ID: \" + str(vector_store.id))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Attached Store Name: Vector Store Auto Attached to Thread\n",
      "Retrieved Attached Store ID: vs_BczptHYs6oRzTNYmeHsjFDIo\n",
      "Retrieved Attached Store Metadata: {'Book1': 'Dracula', 'Book2': 'Frankenstein'}\n",
      "Retrieved Attached Store Expires After: ExpiresAfter(anchor='last_active_at', days=7)\n",
      "\n",
      "\n",
      "Retrieved Attached Store Name: Vector Store Auto Attached to Thread\n",
      "Retrieved Attached Store ID: vs_OH3COfzRDcLMKKLRuDUK1mj0\n",
      "Retrieved Attached Store Metadata: {'Book1': 'Dracula', 'Book2': 'Frankenstein'}\n",
      "Retrieved Attached Store Expires After: ExpiresAfter(anchor='last_active_at', days=7)\n",
      "\n",
      "\n",
      "Retrieved Attached Store Name: Vector Store Auto Attached to Thread\n",
      "Retrieved Attached Store ID: vs_FiJTdq7OSNBdp5UOgWCJoIsE\n",
      "Retrieved Attached Store Metadata: {'Book1': 'Dracula', 'Book2': 'Frankenstein'}\n",
      "Retrieved Attached Store Expires After: ExpiresAfter(anchor='last_active_at', days=7)\n",
      "\n",
      "\n",
      "Retrieved Attached Store Name: Vector Store Auto Attached to Thread\n",
      "Retrieved Attached Store ID: vs_Cj2J7ZDAgyxrc213nN58pjyJ\n",
      "Retrieved Attached Store Metadata: {'Book1': 'Dracula', 'Book2': 'Frankenstein'}\n",
      "Retrieved Attached Store Expires After: ExpiresAfter(anchor='last_active_at', days=7)\n",
      "\n",
      "\n",
      "Retrieved Attached Store Name: Vector Store Auto Attached to Thread When Message File Attached\n",
      "Retrieved Attached Store ID: vs_W0nvRHVEeomtdrpL2PMh1Pne\n",
      "Retrieved Attached Store Metadata: {}\n",
      "Retrieved Attached Store Expires After: ExpiresAfter(anchor='last_active_at', days=7)\n",
      "\n",
      "\n",
      "Retrieved Attached Store Name: Vector Store Auto Attached to Assistant\n",
      "Retrieved Attached Store ID: vs_gG4yDnQuxf5JwD6jPwilnPDz\n",
      "Retrieved Attached Store Metadata: {'Book1': 'Wizard of Oz', 'Book2': 'Alice in Wonderland'}\n",
      "Retrieved Attached Store Expires After: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since we retrieved a list of vector stores in the previous example, let's leverage that list to find a specific vector store\n",
    "# We will look for a vector store with a specific name, like \"Fiction\",  using a regular expression and print its ID\n",
    "\n",
    "\n",
    "# Filter the list to find stores with names that match the pattern \"Fiction\" (case insensitive), ignoring NoneType names\n",
    "list_of_attached_stores = [store for store in more_vector_store_list if store.name is not None and re.search(\"[Aa]ttached\", store.name)]\n",
    "\n",
    "# check to see if we have any stores then show all the attached stores\n",
    "\n",
    "for attached_store in list_of_attached_stores:\n",
    "    \n",
    "    # Now let's retrieve the vector store using the ID of the attached store found\n",
    "    retrieved_attached_vector_store = client.beta.vector_stores.retrieve(vector_store_id=attached_store.id)\n",
    "    \n",
    "    # Print the name and id of the retrieved vector store\n",
    "    if retrieved_attached_vector_store.name is not None:\n",
    "        print(\"Retrieved Attached Store Name: \" + retrieved_attached_vector_store.name)\n",
    "    else:\n",
    "        print(\"Retrieved Attached Store has no name\")\n",
    "        \n",
    "    print(\"Retrieved Attached Store ID: \" + retrieved_attached_vector_store.id)\n",
    "    print(\"Retrieved Attached Store Metadata: \" + str(retrieved_attached_vector_store.metadata))\n",
    "    print(\"Retrieved Attached Store Expires After: \" + str(retrieved_attached_vector_store.expires_after))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted vector store with Name: Vector Store Auto Attached to Thread\n",
      "Deleted vector store with ID: vs_BczptHYs6oRzTNYmeHsjFDIo\n",
      "\n",
      "\n",
      "Deleted vector store with Name: Vector Store Auto Attached to Thread\n",
      "Deleted vector store with ID: vs_OH3COfzRDcLMKKLRuDUK1mj0\n",
      "\n",
      "\n",
      "Deleted vector store with Name: Vector Store Auto Attached to Thread\n",
      "Deleted vector store with ID: vs_FiJTdq7OSNBdp5UOgWCJoIsE\n",
      "\n",
      "\n",
      "Deleted vector store with Name: Vector Store Auto Attached to Thread\n",
      "Deleted vector store with ID: vs_Cj2J7ZDAgyxrc213nN58pjyJ\n",
      "\n",
      "\n",
      "Deleted vector store with Name: Vector Store Auto Attached to Thread When Message File Attached\n",
      "Deleted vector store with ID: vs_W0nvRHVEeomtdrpL2PMh1Pne\n",
      "\n",
      "\n",
      "Deleted vector store with Name: Vector Store Auto Attached to Assistant\n",
      "Deleted vector store with ID: vs_gG4yDnQuxf5JwD6jPwilnPDz\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's delete the vector stores in our list of retrieved vector stores\n",
    "for vector_store in list_of_attached_stores:\n",
    "    try:\n",
    "        # Delete the vector store\n",
    "        client.beta.vector_stores.delete(vector_store_id=vector_store.id)\n",
    "        print(f\"Deleted vector store with Name: {vector_store.name}\" \n",
    "                + f\"\\nDeleted vector store with ID: {vector_store.id}\\n\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deleting the vector store: {e}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
